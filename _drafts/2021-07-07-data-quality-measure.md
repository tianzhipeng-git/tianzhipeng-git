---
layout: post
title: "[译]数据质量工具调研"
date: 2021-07-07 23:23:23
categories: bigdata
tags: bigdata  translation
comments: true
---

高质量的数据是数据分析和数据驱动决策的基础. 这是一篇[数据质量工具的调研综述的论文](https://arxiv.org/abs/1907.08138),翻译一下


(不重要的部分是谷歌机翻的基础上修改的, 重点从第三章开始)

* TOC
{:toc}

# 摘要
高质量的数据是数据分析和数据驱动决策的基础. 在实践场景中, 数据质量和数据预处理/数据profile/清洗和后续的数据继承, 分析等等过程都有关系. 在学术界已经发表了很多关于数据质量评估/数据质量维度指标等的研究, 在本文中, 我们调研了现有数据质量工具的功能范围, 缩小学术研究和业界工具实现间的gap. 通过系统搜索, 我们定位到667个标记为数据质量的软件, 从中选出了13个, 分三方面进行评估.

1. data profiling 数据剖析
2. data qulity measurement metrics 数据质量测量指标
3. continuous data quality monitoring 持续数据质量监控

我们根据自定的筛选条件选出这13个工具, 保证他们是领域无关、开源免费的. 本次调查旨在全面概述最先进的数据质量工具，并揭示其功能增强的潜力。此外，也展现了一些在研究中广泛接受但在工具中极少有实现的概念, 例如一些普遍适用的数据质量指标.

# 1 介绍
数据质量测量是建立数据驱动决策的重要构件, 这类机器决策出现在我们生活的方方面面, 例如基于机器学习的排序算法/工业机器人/自动驾驶等人工智能领域. 同时, 基于人的决策也依赖高质量的数据, 例如决定增加还是缩减某产品的生产, 一般基于销售数据. 尽管数据和决策质量之间存在明显的相关性，但84%的美国CEO担心他们的DQ, 有机构认为糟糕的数据质量导致平均每年1500万美元的损失. 因此DQ不再是‘卫生’问题, 而是对企业运营至关重要, 被认为是**企业数据管理的最大挑战**.

为了增加对数据驱动决策的信任，有必要使用适当的工具来衡量和了解所用数据的质量. DQ测量是全面和战略性DQ改进（即数据清理）的先决条件. 然而，根据德国的一项调查，66%的公司使用 Excel 或 Access 解决方案来验证他们的DQ，63%的公司在没有任何长期DQ管理策略的情况下手动和临时确定他们的DQ。**全面的DQ管理需要一个明确的策略、该策略的持续执行以及实施和自动化该策略的适当工具**。

自1980年代以来一直在进行有关数据质量的研究，从那时起，DQ通常与适用性原则有关, 包含主观性和上下文相关性. 数据质量是一个多维度概念, 它有很多个方面定义(如准确性, 完整性, 时效性), 每个方面又由多个数据质量维度来描述. 每个数据质量维度的达成, 又由一个或多个DQ metrics来量化. DQ metric是一个产生某数值的公式. 

同时, 已经有很多商业/开源/学术的DQ工具被开发出来, 他们各自关注的焦点不同, 提供的功能范围也不同, 因为数据质量这个词是很依赖它所处的上下文的, 大家对这个词的用法并不一致. 尽管关于DQ已经有很多出版物、工具和概念, 但是怎么从一个理论概念映射到一个具体实现上并不清晰, 因此, 如何测量和监控DQ仍是一个没有被回答的问题, 本项调查是对成熟的DQ工具的一次概览, 考察了他们的DQ测量和监控功能, 尝试回答上述问题.

为了科学的拆解问题, 我们进行了系统的搜索, 定位出667个标有数据质量的软件工具, 根据预先定义的排除条件, 选择了13个进行深入调研. 为了系统的评估这些工具的功能范围, 我们开发了一个包含三大类的需求目录 (同摘要).

虽然在调研中我们发现有些工具仅仅提供数据清理和提升的功能, 但我们特别的去关注测量的功能和检测DQ问题的能力. 由于在处理关键内容的产品系统中, 自动化的修改数据是不可能的, 检测和报告数据质量功能才是必需的. 并且, 我们认为需要进行长期持续的监控以保证长期高质量的数据.

本调查的结果不仅是为了DQ专业人士去选择合适的DQ工具, 也突出展现了这些最先进的DQ工具的当前能力. 尤其是DQ工具种类繁多, 通常不清楚能有哪些能力. 本文的主要发现可以总结如下:

1. 尽管DQ工具作为新兴市场正处于活跃开发中, 我们通过调查已经发现了667款相关工具, 其中大部分没有出现在之前的调研中.
2. 其中半数(50.8%)工具都是领域专用的, 这意味着他们只能被用于某些特定类型的数据, 或只能评估某些专有系统的DQ.
3. 16.67%的DQ工具聚焦于数据清洗(data cleansing), 而没有有效评估质量的功能.
4. 大部分被调研的工具能够进行数据剖析(data profiling), 但是考虑到目前调研的状态, 他们在数据剖析上仍有很多需要功能增强的地方, 特别是多维度(多列)分析和依赖检测.
5. 我们没有找到任何一款工具实现了比论文中更多的DQ维度指标. 相同指标的实现上也有很多缺点:  有些只能在属性级别上使用不能聚合, 有些要求严格的难以实现的使用标准, 有些实现存在错误.
6. 在通用DQ工具中, DQ监控被视为高级功能, 只在专业版中提供. 例外是专用的开源DQ监控工具，如Apache Griffin 或MobyDQ，它们支持规则的自动化, 但缺乏预定义的函数和数据剖析功能.

本文的结构如下：第 2 节介绍了进行这项研究的应用方法，包括相关调查、我们的研究问题和工具选择策略。第 3 节概述了数据质量、其测量和监控，并代表了我们的评估框架和需求目录。在第 4 节中，我们描述了已选择用于调查的工具，并讨论了评估。第 5 节总结了结果和经验教训。我们在第 6 节总结了对未来工作的展望。



# 2 调研方法
略
# 3 数据质量和评估框架的理论

尽管存在不同的解释, "数据质量"一词最常被描述为“适用性”, 指的是该主题的高度主观性和上下文依赖性.
信息质量通常被看做数据质量的同义词, 虽然两个词可以清楚地区分, 但在这本文按照同义词处理, 以提高调研覆盖率.

数据质量的核心方法论可被分为以下活动: 
1. 状态重建
2. DQ测量和评估
3. 数据清洗或提升
4. 建立持续DQ监控

并非所有工具都包含这些活动, 也不是只有这些活动, 这些是本文考察重点. 状态重建是指收集数据的上下文信息, 组织架构信息等, 在本文中只讨论data profiling中涉及的部分功能.

<b>数据剖析</b>. 数据剖析是指使用各种技术分析数据集, 以获得关于数据的数据(元数据)的过程. 因此它是在进行任何DQ测量监控活动前的必需任务. 典型的信息如 列中的维一值量, 丢失值量, 数据类型, 出现的模式和频次等. 大多数工具在一定程度上提供了这项能力.

<b>数据质量测量</b>. 根据xx的说法, 数据质量从业者面临的最大挑战是回答如何进行数据质量测量. assessment和measurement含义相近, 在DQ本文中, 同义词处理. 传统上的DQ测量, 被描述为一系列的数据质量维度和对应的指标, 经过多年的讨论, 仍然没有关于维度指标的统一和标准化的结论, 我们在3.1节的需求目录中列明了一些合理的指标.

<b>数据清洗</b>. 数据清洗是指修复数据错误和偏差的过程. 实践中, 自动数据清洗任务包括, 用户数据标准化, 去重, 匹配等. 其他提升数据质量的方式通常需要手动进行. 尽管在海量数据上进行自动数据清洗很有价值, 但它引入了新错误的风险, 这些新错误通常很难理解. 本次调查中没考虑这项功能.

<b>数据质量监控</b>. DQ监控这项功能通常是隐含的, 没有达成统一共识, 数据监控和数据质量监控是不同的, 但是很少被区分开, 本文都包含.

## 3.1 数据质量维度和指标
数据质量通常被描述为一个多维概念, 每个数据质量维度指向数据质量的一个方面. 过去几年提出了很多种数据质量维度分类, 没有达成共识. 本文覆盖了最常用的四个维度.

Piro将DQ维度分为"硬维度"和"软维度". 硬维度包含准确性、完整性和及时性等, 是指可以通过检查程序进行客观测量的. 软维度是指只能通过主观进行评估的. 然而即使是程序检查的硬维度, 也需要实现进行主观的, 领域专有的定义, 以便符合适用性原则.

DQ维度之后就需要提到DQ指标. 指标(metric)是指一个将特定维度转化为一个数值的函数, 可以看做一个数据质量维度达成条件.这类的DQ指标可以在多个聚合级别上策略, 如值级别, 列/属性级别, 记录级, 表级, 数据库级等. 这种聚合可以采用前一级别的指标值进行加权平均数计算. Heinrich等人提出了可靠DQ指标的五项要求: 
- R1 指标值存在最大最小值
- R2 指标值的区间刻度
- R3 配置参数的质量和指标值的确定性
- R4 指标值的合理聚合
- R5 指标值经济合理

然而，其他研究人员声称“需要一种更通用的方法”来评估DQ指标的有用性和有效性。在下文中，我们描述了四个突出的DQ维度及其常用指标。指标列表并非详尽无遗，但应该对在该领域的研究给出一个印象，因为我们在DQ工具评估中观察到此类或类似指标的存在。

### 3.1.1 准确性
虽然准确性有时被认为是最重要的DQ维度, 但是它有多种不同的定义. 在文献中, 准确性是指信息系统和它所建模的现实世界的接近程度, 在自然科学视角中, 准确性是指误差的大小. 我们参考Haegemans关于准确性定义的讨论. 这里提供三个示例:

$$ \text{Free-of-error rating} = \frac{\text{Number of data units in error}}{\text{Total number of data units}} $$

由Lee等人发表, 它还有一个变种, 把错误随机性ROE和错误分布概率PDOE考虑进去.

$$ accuracy = \left ( \frac{NrOfCorrectValues}{TotalNrOfValues}, ROE, PDOE \right ) $$

Hinrichs则提出了如下的准确性公式, 它可以在多个层级聚合. 在属性级别, 准确率指标 is deﬁned by the ratio between a value’s arity and its optimal arity for numeric values. For a numeric attribute A, s opt (A) is the optimal number of digits and decimals for A, w is a value of A and s(w) is the actual number of digits and decimals for w in attribute A. Since s opt (A) is not necessarily maximal, the metric needs to be normalized by ]0, 1] (实在看不懂了)

$$ QGen(w, A) = min \left ( \frac{s(w)}{s_{opt}(A))}, 1 \right ) $$

### 3.1.2 完整性
完整性通常被描述为“数据中包含的信息的广度、深度和范围”, 涵盖了数据完整的条件. Lee等人提供了通用的完整性公式:

$$ \text{number of incomplete elements completeness} = 1 - \frac{\text{number of incomplete elements}}{\text{total number of elements}} $$

需要指出丢失值数量有多种计算方式, 可以把空值考虑进去, 也可以把默认值当做丢失(如0, "NaN").

### 3.1.3 及时性
及时性描述"任务处理的数据要多久到达", 它与数据的更新频率, 数据的失效速度等有关, “及时性可以被解释为属性的值仍旧是up-to-date的可能性”, 时效性指标: 

$$ Q_{Time}^{w}(t) := exp(-decline(A)\cdot t) $$

w是属性的值, decline是衰减率, 代表在指定时间段t内, 平均的失效数据量.

### 3.1.4 一致性
一致性也有多种解释, 根据Batini和Scannapieco, “一致性描述了, 对数据项定义的语义规则的违反”. 这种规则的一个例子是关系型数据中的的完整性约束. 