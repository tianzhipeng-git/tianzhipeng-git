---
layout: post
title: "spark硬核优化一/二 - 布隆过滤器大join优化/limit优化"
date: 2023-10-07 23:23:23
categories: bigdata
tags: bigdata spark
keywords: 布隆过滤器 join执行计划 Spark执行优化 BloomFilter
excerpt: 借助布隆过滤器解决两个大表join的性能问题. 深入分析和解决limit速度过慢的问题?
comments: true
---

分享记录几个在实际工作中解决的几个硬核spark优化的case, 所谓硬核就是不是简单的改改sql/调调配置就能解决的, 需要深入spark内部原理, 修改/扩展spark源码才能实现的优化.

这里是回忆整理了之前的两个case写成博客, 应该是最后一篇关于spark的博客了.

1. 借助布隆过滤器解决两个大表join的性能问题.
2. limit速度为什么这么慢?

* TOC
{:toc}

# 布隆过滤器解决两个大表join
## 场景
我们的业务是程序化广告场景, 在这个业务中, 媒体侧(头腾快百)会将要展现广告的机会实时通过api发送给广告主(通过DSP或者自有RTA的形式), 广告主返回竞价信息. 这个过程产生的数据我们称为`广告请求数据`, 广告主侧可以保存下来. 由于广告主对接多家媒体的很多app, 这个广告请求的量级是相当大的, 每天达到千亿万亿条.

另外, 媒体app中如果真的将某条广告展现给用户了, 媒体还会将展现的信息实时通过api发送给广告主, 这个数据我们称为`广告曝光数据`,

## 布隆过滤器介绍
## 实现
## 效果
# limit速度为什么这么慢?
## 场景&现象
limit语句在日常跑数的时候我们都经常使用, 比如想看一下数据的样子, 一般都会执行

{% highlight sql %}
select * from x limit 100;
{% endhighlight %}

这个语句的执行速度一般都非常快, 秒级别就看到数据展示出来了.

但是有时候有一些场景中, 我们需要limit的量级太大, 用limit就出奇的慢, 比如从一个100亿的表中`limit 1亿`或者从1亿1千万的表中`limit 1亿`都比预想的慢的多, 执行时间都到小时级了.

## 原因


## 解法