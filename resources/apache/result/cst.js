var cst = {
    "Apache Airflow": {
        "chinesedesc": "工作流自动化和调度框架, DAG",
        "programming-language": "Python"
    },
    "Apache Hadoop": {
        "chinesedesc": "什么是大数据事实标准啊?(战术后仰"
    },
    "Apache Druid": {
        "chinesedesc": "大数据OLAP平台, 高性能实时分析数据库"
    },
    "Apache Hive": {
        "chinesedesc": "数仓工具, 元数据管理, SQL on Hadoop"
    },
    "Apache HBase": {
        "chinesedesc": "表面上类似关系数据库(面向列), 实则是Hadoop上的超大规模随机实时读写kv数据库"
    },
    "Apache Spark": {
        "programming-language": "Scala",
        "chinesedesc": "下一代分布式计算引擎, 替代MR"
    },
    "Apache Parquet": {
        "chinesedesc": "列式存储格式"
    },
    "Apache ORC": {
        "chinesedesc": "列式存储格式"
    },
    "Apache Tomcat": {
        "chinesedesc": "Java Servlet容器, Web服务器"
    },
    "Apache Superset": {
        "chinesedesc": "Druid分析工具, BI"
    },
    "Apache ZooKeeper": {
        "chinesedesc": "分布式一致性协调工具"
    },
    "Apache Curator": {
        "chinesedesc": "访问ZK的java client"
    },
    "Apache Zeppelin": {
        "chinesedesc": "交互数据分析可视化工具, 类似jupyter notebook"
    },
    "Apache Calcite": {
        "chinesedesc": "sql解析优化工具, Druid的sql功能就是借助这个实现的"
    },
    "Apache TinkerPop": {
        "chinesedesc": "LPG模型的图数据库的框架, gremlin查询语言"
    },
    "Apache Jena": {
        "chinesedesc": "语义网和链接数据(LOD)的框架, RDF图"
    },
    "Apache Derby": {
        "chinesedesc": "java关系数据库, 小巧内嵌基于文件"
    },
    "Apache Directory Studio": {
        "chinesedesc": "LDAP浏览器"
    },
    "Apache HttpComponents Core": {
        "chinesedesc": "java http客户端库"
    },
    "Apache HttpComponents Client": {
        "chinesedesc": "java http客户端库"
    },
    "Apache Velocity": {
        "chinesedesc": "java 模板引擎"
    },
    "Apache POI": {
        "chinesedesc": "java 操作office文件格式"
    },
    "Apache Commons Codec": {
        "chinesedesc": "common库之编解码, base32/64, url, hex"
    },
    "Apache Commons CLI": {
        "chinesedesc": "common库之CLI, 编写命令行程序, 参数解析等"
    },
    "Apache Commons Compress": {
        "chinesedesc": "common库之压缩, tar,zip,gzip,XZ,Pack200,bzip2,7z,arj,lzma,snappy,DEFLATE,lz4"
    },
    "Apache Commons DBCP": {
        "chinesedesc": "common库之数据库连接池"
    },
    "Apache Commons IO": {
        "chinesedesc": "common库之IO操作"
    },
    "Apache Commons Lang": {
        "chinesedesc": "common库之java通用工具库"
    },
    "Apache Commons Logging": {
        "chinesedesc": "common库之日志框架, jcl"
    },
    "Apache Commons Math": {
        "chinesedesc": "common库之数学运算"
    },
    "Apache Commons BeanUtils": {
        "chinesedesc": "common库之JavaBeans操作库"
    },
    "Apache Log4j 2": {
        "chinesedesc": "java日志框架"
    },
    "Apache Struts": {
        "chinesedesc": "老掉牙web框架"
    },
    "Apache Maven": {
        "chinesedesc": "java依赖管理, 打包工具"
    },
    "Apache Ant": {
        "chinesedesc": "上一代java依赖管理, 打包工具"
    },
    "Apache Groovy": {
        "chinesedesc": "jvm上的胶水语言"
    },
    "Apache Kafka": {
        "chinesedesc": "消息队列, 数据管道, 流式平台"
    },
    "Apache RocketMQ": {
        "chinesedesc": "消息队列",
        "programming-language": "Java"
    },
    "Apache ActiveMQ": {
        "chinesedesc": "消息队列",
        "programming-language": "Java"
    },
    "Apache Thrift": {
        "chinesedesc": "跨语言服务通信, RPC",
        "programming-language": "C++"
    },
    "Apache Beam" : {
        "chinesedesc": "提供统一的数据处理编程框架，支持批处理和流处理, 可运行在MR/Spark/Flink等引擎上",
    },
    "Apache Oozie": {
        "chinesedesc": "yarn上的工作流调度系统",
    },
    "Apache Accumulo" : {
        "chinesedesc": "基于HDFS和ZK的分布式kv存储系统, 类似HBase",
    },
    "Apache Ambari" : {
        "chinesedesc": "Hadoop集群部署管理工具",
    },
    "Apache Avro" : {
        "chinesedesc": "序列化框架",
    },
    "Apache Bigtop" : {
        "chinesedesc": "大数据打包测试工具",
    },
    "Apache BookKeeper" : {
        "chinesedesc": "为实时负责进行优化的, 分布式存储服务(日志存储服务), Namenode和Pulsar用它做数据存储",
    },
    "Apache Camel" : {
        "chinesedesc": "灵活的消息媒介引擎, 基于POJO的企业集成模式(Enterprise Integration Patterns)的实现, 参考Spring Integration",
    },
    "Apache CarbonData" : {
        "chinesedesc": "带索引的列式存储格式, Huawei开源",
    },
    "Apache CouchDB" : {
        "chinesedesc": "文档型NoSQL数据库, 支持JSON/HTTP访问",
    },
    "Apache Flume" : {
        "chinesedesc": "日志数据采集,聚合,传输工具",
    },
    "Apache Sqoop" : {
        "chinesedesc": "数据传输工具, 一般用于Hadoop和关系数据库之间",
    },
    "Apache Storm" : {
        "chinesedesc": "分布式实时计算引擎, 流处理框架",
    },
    "Apache Samza" :{
        "chinesedesc": "分布式实时计算引擎, 流处理框架",
    },
    "Apache Tez" :{
        "chinesedesc": "通用的复杂DAG计算和数据处理框架, 在Hive中用于替代简单MR, 被Spark替代",
    },
    "Apache Flink" :{
        "chinesedesc": "分布式实时计算引擎, 流处理框架",
    },
    "Apache Hudi" :{
        "chinesedesc": "HDFS之上的数据增删改层, 数据湖, 流式增量",
    },
    "Apache Phoenix" :{
        "chinesedesc": "OLTP和SQL on Hadoop, 最初是SQL查HBase的",
    },
    "Apache Drill" :{
        "chinesedesc": "又一个SQL on Hadoop, MPP, 有自己的集群比Hive快",
    },
    "Apache Ignite" :{
        "chinesedesc": "内存为主的分布式数据库",
    },
    "Apache Kudu" :{
        "chinesedesc": "列式存储管理器? OLAP系统, 类似HBase, 和Impala配合较好",
    },
    "Apache Impala" :{
        category: "big-data",
        "chinesedesc": "又一个SQL on Hadoop, MPP, 有自己的集群比Hive快",
    },
    "Apache REEF" :{
        "chinesedesc": "编写运行于Yarn这种资源管理集群上的程序的工具库, 实现MyCode on Yarn",
    },
    "Apache MXNet" :{
        "chinesedesc": "深度学习框架",
    },
    "Apache OODT" :{
        "chinesedesc": "看起来老掉牙的数据管理系统, NASA贡献...",
    },
    "Apache Knox" :{
        "chinesedesc": "Hadoop集群各组件接口的反向代理网关",
    },
    "Apache Kibble" :{
        "chinesedesc": "软件项目的活动报告分析平台, (分析git、邮件列表、JIRA等的东西, 生成报告)",
    },
    "Apache Hop" :{
        "chinesedesc": "ETL管理工具, kettle新分支",
    },
    "Apache Airavata" :{
        "chinesedesc": "科学网关, 用于调度使用网格计算中的计算/存储等资源",
    },
    "Apache Daffodil" :{
        "chinesedesc": "数据格式描述语言, 描述和转换各种JOSN/XML, 自己转格式挺方便",
    },
    "Apache DataFu" :{
        "chinesedesc": "Hadoop上的数据挖掘统计库",
    },
    "Apache Giraph" :{
        "chinesedesc": "迭代式的图计算框架, 运行于Hadoop上",
    },
    "Apache Helix" :{
        "chinesedesc": "集群管理框架, 帮助实现分区/复制/故障检测恢复/监控等等功能, 不同于Yarn, 不同于REEF",
    },
    "Apache Fluo" :{
        "chinesedesc": "增量数据处理系统, 将新数据连续地合并到大型现有数据集, 类似但不同于Flink这种. 使用Accumulo做存储",
    },
    "Apache Livy (Incubating)" : {
        "chinesedesc": "用REST方式提交Spark",
    },
}